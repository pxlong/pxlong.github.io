<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0041)https://people.eecs.berkeley.edu/~cbfinn/ -->
<html>
    <head>
        <!-- meta http-equiv="Content-Type" content="text/html; charset=windows-1252" / -->
        <!-- meta name="viewport" content="width=device-width, initial-scale=1.0" / -->
        <meta name="viewport" content="width=800" />
        <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org" />
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    heading2 {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 18px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 42px;
    }
    li:not(:last-child) {
        margin-bottom: 5px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="./pxlong_files/icon.png">
  <title>Pinxin Long</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">

  <link href="./pxlong_files/css" rel="stylesheet" type="text/css">
  <style id="dark-reader-style" type="text/css">@media screen {

/* Leading rule */
html {
  -webkit-filter: brightness(110%) contrast(90%) grayscale(20%) sepia(10%) !important;
}

/* Text contrast */
html {
  text-shadow: 0 0 0 !important;
}

/* Full screen */
*:-webkit-full-screen, *:-webkit-full-screen * {
  -webkit-filter: none !important;
}

/* Page background */
html {
  background: rgb(255,255,255) !important;
}

}</style></head>

<body>
    <div id="StayFocusd-infobar" style="display: none; top: 2400px;">
        <img src="chrome-extension://laankejkbhbdhmipfmgcngdelahlfoji/common/img/eye_19x19_red.png">
        <span id="StayFocusd-infobar-msg"></span>
        <span id="StayFocusd-infobar-links">
            <a id="StayFocusd-infobar-never-show">hide forever</a>&nbsp;&nbsp;|&nbsp;&nbsp;
            <a id="StayFocusd-infobar-hide">hide once</a>
        </span>
    </div>

  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
      <tbody>
          <tr>
              <td>
                  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                      <tbody><tr>
                          <td width="75%" valign="middle">
                              <p align="center">
                                  <name>Pinxin Long</name><br>
                                  pinxinlong at gmail dot com
                              </p>
                              <p>
                                  I was a research scientist at <a href="http://www.dorabot.com/" target="_blank">Dorabot Inc.</a>, where I work on multi-robot systems. 
                                  Before that, I spent half a year at the<a href="http://www.cityu.edu.hk" target="_blank"> City University of Hong Kong (CityU)</a> , 
                                  supervised by <a href="https://sites.google.com/site/panjia/" target="_blank">Prof. Jia Pan</a> on multi-agent collision avoidance.
                                  And ever since then, I've been collaborating with <a href="https://sites.google.com/site/panjia/" target="_blank">Prof. Jia Pan</a> on machine learning
                                  for robotic perception and control.
                              </p>
                              <p>
                                  Before CityU, I worked as a research assitant in <a href="http://vcc.szu.edu.cn/" target="_blank">Visual Computing Center (VCC)</a> at
                                  <a href="http://www.siat.ac.cn/" target="_blank">
                                  Shenzhen Institutes of Advanced Technology (SIAT)</a>, <a href="http://www.cas.cn/" target="_blank">Chinese Academy of Science (CAS)</a>, where I involved in
                                  several research projects, including two exciting robotic auto-scanning projects with the <a href="http://www.willowgarage.com/pages/pr2/overview" target="_blank">
                                      PR2 robot</a>.
                                  Before coming to Shenzhen, I received a Bachelor's degree in Automation at
                                  <a href="http://www.uestc.edu.cn/" target="_blank">UESTC</a>, you can find some videos about my undergraduate projects below.
                              </p>
                              <p>
                                  <strong>
                                      I am looking for a full time job in the <I>*Autonomous Driving*</I> industry.
                                      <!-- I will be available to start work after 2017-09-15. -->
                                      If you are interested in talking with me about any work opportunities,
                                      please feel free to <a href="mailto:pinxinlong@gmail.com">drop me a line</a>.
                                  </strong>
                              </p>
                              <p align="center">
                                  <a href="./pxlong_files/cv.pdf" target="_blank">CV</a> &nbsp;/&nbsp;
                                  <a href="https://scholar.google.com/citations?user=m3tbW2kAAAAJ&hl=en" target="_blank">Google Scholar</a> &nbsp;/&nbsp;
                                  <a href="http://www.github.com/pxlong/" target="_blank"> GitHub </a>
                              </p>
                          </td>
                          <td width="25%">
                               <img src="./pxlong_files/pxlong_small.png">
                               <p align="center">&copy;  Mavis Chen 2017 </p>
                          </td>
                      </tr>
                      </tbody>
                  </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
              <tr>
                  <td>
                      <heading>News</heading>
                      <ul>
                          <li> 2017.06.02 - I presented our work on exploring deep neural networks for multi-robot navigation in the
                              <a href="http://webdiis.unizar.es/~edumonti/17_ICRA_WS/cfp.html" target="_blank">
                              Multi-robot Perception-Driven Control and Planning Workshop</a> at ICRA 2017.</li>
                          <li> 2016.12.09 - I presented our work on multi-agent collision avoidance in the
                              <a href="https://sites.google.com/site/malicnips2016/" target="_blank">
                              Learning, Inference and Control of Multi-Agent Systems Workshop</a> at NIPS 2016.</li>
                      </ul>
                  </td>
              </tr>


        <tr>
            <td width="100%" valign="middle">
                <heading>Interests</heading>
                <p>
                    My career/research interests lie in the intersection of autonomous driving, robotics, deep learning and reinforcement learning.
                    In particular, I'm interested in designing machine learning algorithms to learn a driving policy that can enable robotic cars
                    driving safely, reliably and efficiently in complex environments.
                </p>
            </td>
        </tr>
        </tbody>
      </table>

     <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
         <tbody>

             <tr onmouseout="drl_stop()" onmouseover="drl_start()">
                 <td width="25%">
                     <heading>Publications</heading><br><br>
                     <div class="one">
                         <div class="two" id="drl_image" style="opacity: 0;"><img src="./pxlong_files/drlmrca.gif" width="150" height="143"></div>
                         <img src="./pxlong_files/drlmrca.png" width="150" height="143">
                     </div>
                     <script async="" src="./pxlong_files/analytics.js">
                     </script>
                     <script type="text/javascript">
                      function drl_start() {
                          document.getElementById('drl_image').style.opacity = "1";
                      }
                      function drl_stop() {
                          document.getElementById('drl_image').style.opacity = "0";
                      }
                      drl_stop()
                     </script>
                 </td>
                 <td valign="top" width="75%">
                     <heading2><i></i></heading2><br>
                     <p>
                         <papertitle>Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning</papertitle><br>
                         <strong>Pinxin Long*</strong>, 
                         Tingxiang Fan*,
                         Xinyi Liao,
                         Wenxi Liu,
                         <a href="https://sites.google.com/site/panjia/" target="_blank">Jia Pan</a> <br>
                         <em>In Preparation</em>, 2017 <br>
                         project
                         /
                         code
                         /
                         arXiv <br><br>
                         * authors contributed equally
                     </p><p></p>
                     <p> 
                     </p>
                 </td>
             </tr>


             <tr onmouseout="deepmaca_stop()" onmouseover="deepmaca_start()">
                 <td width="25%">
                     <heading2><i></i></heading2><br>
                     <div class="one">
                         <div class="two" id="deepmaca_image" style="opacity: 0;"><img src="./pxlong_files/deepmaca.gif" width="150" height="134"></div>
                         <img src="./pxlong_files/deepmaca.png" width="150" height="134">
                     </div>
                     <script type="text/javascript">
                      function deepmaca_start() {
                          document.getElementById('deepmaca_image').style.opacity = "1";
                      }
                      function deepmaca_stop() {
                          document.getElementById('deepmaca_image').style.opacity = "0";
                      }
                      deepmaca_stop()
                     </script>
                 </td>
                 <td valign="top" width="75%">
                     <p><a href="https://arxiv.org/pdf/1609.06838.pdf" target="_blank">
                         <papertitle>Deep-Learned Collision Avoidance Policy for Distributed Multi-Agent Navigation</papertitle></a><br>
                         <strong>Pinxin Long</strong>,  Wenxi Liu,
                         <a href="https://sites.google.com/site/panjia/" target="_blank">Jia Pan</a> <br>
                         <em>IEEE Robotics and Automation Letters (RAL)</em>, 2017 <br>
                         <a href="https://sites.google.com/view/deepmaca/" target="_blank">project</a>
                         /
                         <a href="https://arxiv.org/abs/1609.06838" target="_blank">arXiv</a>
                     </p><p></p>
                     <p>
                         This paper is our first step toward learning a reactive
                         collision avoidance policy for multi-agent collision avoidance. By carefully designing the data collection process
                         and leveraging an end-to-end learning framework, our method
                         can learn a deep neural network based collision avoidance
                         policy which demonstrates an advantage over the state-of-theart ORCA policy in terms of ease of use (no parameter tuning),
                         success rate, and navigation performance.
                     </p>
                 </td>
             </tr>


             <tr onmouseout="dorapicker_stop()" onmouseover="dorapicker_start()">
                 <td width="25%">
                     <div class="one">
                         <div class="two" id="dorapicker_image" style="opacity: 0;"><img src="./pxlong_files/dorapicker.gif"></div>
                         <img src="./pxlong_files/dorapicker.png">
                     </div>
                     <script type="text/javascript">
                      function dorapicker_start() {
                          document.getElementById('dorapicker_image').style.opacity = "1";
                      }
                      function dorapicker_stop() {
                          document.getElementById('dorapicker_image').style.opacity = "0";
                      }
                      dorapicker_stop()
                     </script>
                     
                 </td>
                 <td valign="top" width="75%">
                     <p><a href="https://arxiv.org/pdf/1603.06317.pdf" target="_blank">
                         <papertitle>DoraPicker: An Autonomous Picking System for General Objects</papertitle></a><br>
                         Hao Zhang, <strong>Pinxin Long</strong>, Hao Zhang, Pinxin Long, Dandan Zhou, Zhongfeng Qian, Zheng Wang,
                         <a href="https://sites.google.com/site/weiweilab/" target="_blank">Weiwei Wan</a>,
                         <a href="http://www.cs.unc.edu/~dm/" target="_blank">Dinesh Manocha</a>, Chonhyon Park, Tommy Hu, Chao Cao, Yibo Chen, Marco Chow,
                         <a href="https://sites.google.com/site/panjia/" target="_blank">Jia Pan</a> <br>
                         <em>International Conference on Automation Science and Engineering (CASE)</em>, 2016 <br>
                         <!--  <strong style="color:green">Best Cognitive Robotics Paper Finalist</strong><br>-->
                         <a href="http://arxiv.org/abs/1603.06317" target="_blank">arXiv</a>
                         /
                         <a href="https://www.youtube.com/watch?v=E-rI2hBMRpk&feature=youtu.be" target="_blank">video</a>
                     </p><p></p>
                     <p>
                         We present our pick-and-place system in detail while highlighting
                         our design principles for the warehouse settings, including
                         the perception method that leverages knowledge about its
                         workspace, three grippers designed to handle a large variety of
                         different objects in terms of shape, weight and material, and
                         grasp planning in cluttered scenarios.
                     </p>
                 </td>
             </tr>
             

             <tr onmouseout="scene_stop()" onmouseover="scene_start()">
                 <td width="25%">
                     <div class="one">
                         <div class="two" id="scene_image" style="opacity: 0;"><img src="./pxlong_files/scene2.png"></div>
                         <img src="./pxlong_files/scene1.png">
                     </div>
                     <script type="text/javascript">
                      function scene_start() {
                          document.getElementById('scene_image').style.opacity = "1";
                      }
                      function scene_stop() {
                          document.getElementById('scene_image').style.opacity = "0";
                      }
                      scene_stop()
                     </script>
                 </td>
                 <td width="75%" valign="top">
                     <p><a href="http://kevinkaixu.net/papers/shi_cag15_scene.pdf" target="_blank" id="scene">
                         <papertitle>Data-Driven Contextual Modeling for 3D Scene Understanding</papertitle></a><br>
              <a href="http://www.yifeishi.net/" target="_blank">Yifei Shi</a>, <strong>Pinxin Long</strong>,
              <a href="http://kevinkaixu.net/" target="_blank">Kai Xu</a>, <a href="http://vcc.szu.edu.cn/~huihuang/" target="_blank">Hui Huang</a>, Yueshan Xiong <br>
              <em>Computer & Graphics (C&G)</em>, 2016<br>
              <a href="http://vcc.szu.edu.cn/research/2016/SceneModeling/" target="_blank">project</a>
                     </p>
                     <p>
                         We propose a data-driven approach to modeling contextual information
                         covering both intra-object part relations and inter-object object layouts.
                         Our method combines the detection of individual objects and object groups within the same framework,
                         enabling contextual analysis without knowing the objects in the scene a priori.
                     </p>
                 </td>
             </tr>
             
             <tr onmouseout="plant_stop()" onmouseover="plant_start()">
                 <td width="25%">
                     <div class="one">
                         <div class="two" id="plant_image" style="opacity: 0;"><img src="./pxlong_files/plant2.png"></div>
                    <img src="./pxlong_files/plant1.png">
                     </div>
                     <script type="text/javascript">
                      function plant_start() {
                     document.getElementById('plant_image').style.opacity = "1";
                      }
                      function plant_stop() {
                          document.getElementById('plant_image').style.opacity = "0";
                      }
                      plant_stop()
                     </script>
                 </td>
                 <td width="75%" valign="top">
                     <p><a href="http://kangxue.org/papers/plantCut.pdf" id="plant" target="_blank">
                         <papertitle>Full 3D Plant Reconstruction via Intrusive Acquisition</papertitle></a><br>
                         <a href="http://kangxue.org" target="_blank">Kangxue Yin</a>, <a href="http://vcc.szu.edu.cn/~huihuang/" target="_blank">Hui Huang</a>, 
                         <strong>Pinxin Long</strong>, Alexei Gaissinski, 
                         <a href="http://www.cs.mun.ca/~gong/" target="_blank">Minglun Gong</a>, 
                         <a href="https://www.cs.bgu.ac.il/~asharf/" target="_blank">Andrei Sharf</a>
                         <em>Computer Graphics Forum</em>, 2016<br>
                         <a href="http://vcc.szu.edu.cn/research/2016/PlantCut/" target="_blank">project</a>
                         /
                         <a href="https://drive.google.com/open?id=0B1yWc4B_DEqPbnpWUGdoWGNwSVk" target="_blank">data</a>
                     </p>
                     <p>
                         We present an intrusive acquisition approach for acquiring and modeling of plants and foliage,
                         which disassembles the plant into disjoint parts that can be accurately scanned and reconstructed offline.
                     </p>
                 </td>
             </tr>
             
             <tr onmouseout="pr2scene_stop()" onmouseover="pr2scene_start()">
                 <td width="25%">
                     <div class="one">
                         <div class="two" id="pr2scene_image" style="opacity: 0;"><img src="./pxlong_files/pr2scene.gif"></div>
                    <img src="./pxlong_files/pr2scene.png">
                     </div>
                     <script type="text/javascript">
                      function pr2scene_start() {
                     document.getElementById('pr2scene_image').style.opacity = "1";
                      }
                      function pr2scene_stop() {
                          document.getElementById('pr2scene_image').style.opacity = "0";
                      }
                      pr2scene_stop()
                     </script>
                 </td>
                 <td valign="top" width="75%">
                     <p><a href="http://kevinkaixu.net/papers/xu_siga15_pr2scene.pdf" target="_blank">
                         <papertitle>Autoscanning for Coupled Scene Reconstruction and Proactive Object Analysis</papertitle></a><br>
                         <a href="http://kevinkaixu.net/" target="_blank">Kai Xu</a>, <a href="http://vcc.szu.edu.cn/~huihuang/" target="_blank">Hui Huang</a>,
                         <a href="http://www.yifeishi.net/" target="_blank">Yifei Shi</a>, <a href="http://haoli-china.github.io/Personal-Homepage/" target="_blank">Hao Li</a>,
                         <strong>Pinxin Long</strong>, Jianong Caichen,
                         Wei Sun, <a href="http://www.cs.sdu.edu.cn/~baoquan/" target="_blank">Baoquan Chen</a> <br>
                         <em>ACM Transactions on Graphics (SIGGRAPH Asia 2015)</em>, 2015 <br>
                         <!--  <strong style="color:green">Best Cognitive Robotics Paper Finalist</strong><br>-->
                         <a href="http://kevinkaixu.net/projects/pr2scene.html" target="_blank">project</a>
                         /
                         <a href="http://kevinkaixu.net/slides/xu_siga15_pr2scene.pdf" target="_blank">slides</a>
                         /
                         <a href="https://youtu.be/p26YuYVC0YI" target="_blank">video (youtube)</a>, 
                         <a href="http://v.youku.com/v_show/id_XMTMwNzYwNzQyMA==.html" target="_blank">video (youku)</a>
                         /
                         <a href="https://www.dropbox.com/s/wj3ezjjmlt6olj9/pr2scene_code.zip?dl=0" target="_blank">code</a>
                     </p><p></p>
                     <p>
                         We propose autonomous scene scanning by a robot to relieve humans from such a tedious task.
                         The presented algorithm interleaves between scene analysis for extracting objects and robot conducted validation for
                         improving the segmentation and object-aware reconstruction.
                     </p>
                 </td>
             </tr>
             
             <tr onmouseout="autoscan_stop()" onmouseover="autoscan_start()">
                 <td width="25%">
                     <div class="one">
                         <div class="two" id="autoscan_image" style="opacity: 0;"><img src="./pxlong_files/autoscan.gif"></div>
                         <img src="./pxlong_files/autoscan.png">
                     </div>
                     <script type="text/javascript">
                      function autoscan_start() {
                          document.getElementById('autoscan_image').style.opacity = "1";
                      }
                      function autoscan_stop() {
                          document.getElementById('autoscan_image').style.opacity = "0";
                      }
                      autoscan_stop()
                     </script>
                 </td>
                 <td valign="top" width="75%">
                     <p><a href="http://vcc.szu.edu.cn/commons/fileupload/upload.do?method=download&uploadId=2068">
                         <papertitle>Quality-driven Poisson-guided Autoscanning</papertitle></a><br>
                         <a href="http://shihaowu.net/" target="_blank">Shihao Wu</a>, Wei Sun, <strong>Pinxin Long</strong>, 
                         <a href="http://vcc.szu.edu.cn/~huihuang/" target="_blank">Hui Huang</a>, 
                         <a href="http://www.math.tau.ac.il/~dcor/" target="_blank">Daniel Cohen-Or</a>, 
                         <a href="http://www.cs.mun.ca/~gong/" target="_blank">Minglun Gong</a>, 
                         <a href="https://www.cgmi.uni-konstanz.de/" target="_blank">Oliver Deussen</a>, 
                         <a href="http://www.cs.sdu.edu.cn/~baoquan/" target="_blank">Baoquan Chen</a> <br>
                         <em>ACM Transactions on Graphics (SIGGRAPH Asia 2014)</em>, 2014 <br>
                         <!--  <strong style="color:green">Best Cognitive Robotics Paper Finalist</strong><br>-->
                         <a href="http://vcc.szu.edu.cn/research/2014/Autoscan/" target="_blank">project</a>
                         /
                         <a href="https://www.dropbox.com/s/3etdpiaybtd54x9/autoscan.pptx?dl=0" target="_blank">slides</a>
                         /
                         <a href="https://www.youtube.com/watch?v=BLX4LbiUtSQ" target="_blank">video (youtube)</a>, 
                         <a href="http://v.youku.com/v_show/id_XNzQ0NTY0Mzk2.html?spm=a2h0k.8191407.0.0&from=s1.8-1-1.2" target="_blank">video (youku)</a>
                         /
                         <a href="https://www.youtube.com/watch?v=hZJNEYyxYtk" target="_blank">live show</a>
                         /
                         <a href="http://vcc.siat.ac.cn/commons/fileupload/upload.do?method=download&uploadId=1532">code</a>
                     </p><p></p>
                     <p>
                         We propose a quality-driven, Poisson-guided autonomous scanning method to ensure the high quality scanning of the model.
                         This goal is achieved by placing the scanner at strategically selected Next-Best-Views (NBVs) to ensure progressively capturing the
                         geometric details of the object, until both completeness and high fidelity are reached.
                     </p>
                 </td>
             </tr>

         </tbody>
     </table>

     <table width="100%" align="center" border="0" cellpadding="20">
         <tbody>
             <tr>
                 <td width="100%" valign="top">
                     <heading>Old Projects</heading>
                     <p>
                         <papertitle>Quadruped Robots</papertitle> <br>
                         Pinxin Long, Hongjin Yu, Haoxing Guo, Ke Zhao, 2010 - 2011
                     </p>
                     <p>
                         We designed several quadruped robots from scratch and implemented discrete reaching movement
                         and rhythmic movements (four different gaits) on these robots using Central Pattern Generator based
                         locomotion control methods. <br>
                     </p>
                     <div style='text-align: center; margin: 0 auto'>
                         <iframe width="440" height="247.5" src="https://www.youtube.com/embed/9zPuFaZ4egA" frameborder="0" allowfullscreen></iframe>
                     </div>
                 </td>

             </tr>
         </tbody>
     </table>

     <table width="100%" align="center" border="0" cellpadding="20">
         <tbody>
             <tr>
                 <td width="100%" valign="top">
                     <p>
                         <papertitle>Speech Controlled Mobile Robot</papertitle> <br>
                         Pinxin Long, Ke Zhao, Jian Zheng, 2010
                     </p>
                     <p>
                         We created a robot using STM32 and LD3320 chips running Chinese Speech Recognition application.
                         This application enables the robot to perform various movement (e.g. move forward, turn left, stop, etc.)
                         based upon user interaction by speech. <br>
                     </p>
                     <div style='text-align: center; margin: 0 auto'>
                         <iframe width="440" height="247.5" src="https://www.youtube.com/embed/-rig5GvlBhI" frameborder="0" allowfullscreen></iframe>
                     </div>
                 </td>
             </tr>
         </tbody>
     </table>

     <table width="100%" align="center" border="0" cellpadding="20">
         <tbody>
             <tr>
                 <td width="100%" valign="center">
                     <heading>Notes</heading>
                     <p>
                         <heading2>Autonomous Driving</heading2> <br>
                         Route Planning
                         /
                         Behavioral Decision
                         /
                         Motion Planning
                         /
                         Local Feedback Control
                         <br><br>

                         <heading2>Robotics</heading2> <br>
                         Localization
                         <!-- <a href="./pxlong_files/localization.pdf"></a> -->
                         <!--    / Mapping
                         <a href="./pxlong_files/mapping.pdf"></a> -->
                         / Planning
                         <!-- <a href="./pxlong_files/planning.pdf"></a> -->
                         / Control
                         <!-- <a href="./pxlong_files/control.pdf"></a> -->
                         <br><br>

                         <heading2>Reinforcement Learning</heading2> <br>
                         Policy Graident
                         <!-- <a href="./pxlong_files/pg.pdf"></a> -->
                         / Driving Policy
                         <!-- <a href="./pxlong_files/vr.pdf"></a> -->
                         / Safety RL
                         <br><br>

                         <heading2>Deep Learning</heading2> <br>
                         Optimization
                         <!-- <a href="./pxlong_files/opt.pdf"></a> -->
                         / Overfitting
                         <!-- <a href="./pxlong_files/of.pdf"></a> -->
                         <br><br>

                         <heading2>Libraries</heading2> <br>
                         Tensorflow (basics, advanced topics, effective guide)
                         /
                         GPU
                         <br><br>

                     </p>
                 </td>
             </tr>
         </tbody>
     </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
              <tr>
                  <td>
                      <br>
                      <p align="right"><font size="2">
                          <a href="https://jonbarron.info/" target="_blank">This nice webpage is "stolen" from here.</a>
                      </font>
                      </p>
                  </td>
              </tr>
          </tbody>
      </table>

      <script>
       (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
           (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
       })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
       
       ga('create', 'UA-104877365-1', 'auto');
       ga('send', 'pageview');
      </script>
              </td>
          </tr>
      </tbody>
  </table>

</body>
</html>
